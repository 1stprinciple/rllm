# Agent API Reference

This page provides detailed API documentation for all agents in rLLM.

## Base Classes

### BaseAgent

The abstract base class that all agents inherit from.

```python
from rllm.agents.agent import BaseAgent, Step, Trajectory
```

#### Methods

##### `update_from_env(observation, reward, done, info, **kwargs)`

Updates the agent's internal state after an environment step.

**Parameters:**
- `observation` (Any): The observation from the environment
- `reward` (float): The reward received after taking the action
- `done` (bool): Whether the episode has ended
- `info` (Dict): Additional metadata from the environment
- `**kwargs`: Additional keyword arguments

**Returns:** None

##### `update_from_model(response, **kwargs)`

Updates the agent's internal state based on the model's response.

**Parameters:**
- `response` (Any): The response from the language model (string or structured response)
- `**kwargs`: Additional keyword arguments

**Returns:** None

##### `reset()`

Resets the agent's internal state for a new episode.

**Returns:** None

##### `get_current_state()`

Returns the agent's current state as a Step object.

**Returns:** `Step` - The current step containing observation, action, reward, etc.

#### Properties

##### `chat_completions`

Returns the current message history in OpenAI chat completion format.

**Returns:** `List[Dict[str, str]]` - List of messages with roles and content

##### `trajectory`

Returns the agent's trajectory containing all steps.

**Returns:** `Trajectory` - The complete trajectory of the current episode

##### `prompt`

Returns the messages for the next model prompt (defaults to `chat_completions`).

**Returns:** `List[Dict[str, str]]` - Messages formatted for model input

---

### Step

Represents a single interaction step in an agent's trajectory.

```python
from rllm.agents.agent import Step
```

#### Attributes

- `observation` (Any): The observation received from the environment
- `thought` (str): The agent's reasoning or thought process
- `action` (Any): The action taken or generated by the agent
- `reward` (float): The reward received for the action
- `next_observation` (Any): The observation resulting from the action
- `done` (bool): Whether the episode ended after this step
- `info` (Dict): Additional information from the environment
- `step` (int): The step number in the episode
- `model_response` (str): The raw response from the language model
- `mc_return` (float): Monte Carlo estimate of returns

---

### Trajectory

Contains a sequence of steps representing an episode.

```python
from rllm.agents.agent import Trajectory
```

#### Attributes

- `steps` (List[Step]): List of steps in the trajectory
- `reward` (float): Total reward for the trajectory

#### Methods

##### `to_dict()`

Converts the trajectory to a dictionary format.

**Returns:** `Dict` - Dictionary representation of the trajectory

---

## Agent Implementations

### MathAgent

Agent specialized for mathematical problem solving with step-by-step reasoning.

```python
from rllm.agents import MathAgent
```

#### Constructor

```python
MathAgent(remove_thinking=False)
```

**Parameters:**
- `remove_thinking` (bool): Whether to remove `<think>` tags from responses. Default: False

#### Attributes

- `instruction` (str): The instruction appended to math problems
- `remove_thinking` (bool): Flag for thinking tag removal

#### Example Usage

```python
agent = MathAgent(remove_thinking=False)

# The agent automatically formats problems with step-by-step instructions
# and expects final answers in \boxed{} format
```

---

### ToolAgent

Agent that can use external tools via function calling interfaces.

```python
from rllm.agents import ToolAgent
```

#### Constructor

```python
ToolAgent(parser_name="qwen", tools=[])
```

**Parameters:**
- `parser_name` (str): Name of the tool parser to use. Default: "qwen"
- `tools` (List): List of tools available to the agent. Default: []

#### Attributes

- `system_prompt` (str): The system prompt for tool usage
- `tools` (MultiTool): Multi-tool interface for managing available tools
- `tool_parser`: Parser for extracting tool calls from model responses
- `tools_prompt` (str): Formatted prompt describing available tools

#### Example Usage

```python
from rllm.tools import get_available_tools

tools = get_available_tools(["calculator", "web_search"])
agent = ToolAgent(parser_name="qwen", tools=tools)

# Agent can now use tools based on model responses
```

---

### WebAgent

Agent for web interaction tasks using BrowserGym.

```python
from rllm.agents import WebAgent
```

#### Constructor

```python
WebAgent()
```

#### Attributes

- `chat_mode` (bool): Whether to use chat-based interactions. Default: False
- `use_html` (bool): Whether to include HTML in observations. Default: False
- `use_axtree` (bool): Whether to include accessibility tree. Default: True
- `use_screenshot` (bool): Whether to include screenshots. Default: False
- `action_set`: BrowserGym action set for web interactions
- `action_history` (List[str]): History of all actions taken
- `accumulate_thinking` (bool): Whether to accumulate thinking content. Default: False
- `cot_prompt` (bool): Whether to use chain-of-thought prompting. Default: False
- `full_conversation` (bool): Whether to use full conversation history. Default: False

#### Methods

##### `get_system_msgs(obs)`

Creates system messages based on observation.

**Parameters:**
- `obs` (Dict): The observation dictionary

**Returns:** `List[Dict]` - List of system messages

##### `get_user_msgs(user_obs)`

Creates user messages from observation.

**Parameters:**
- `user_obs` (Dict): The user observation

**Returns:** `List[Dict]` - List of user messages

#### Example Usage

```python
agent = WebAgent()
agent.use_html = True
agent.use_screenshot = True

# Configure for different observation modes
```

---

### CompetitionCodingAgent

Agent for competitive programming and code generation tasks.

```python
from rllm.agents import CompetitionCodingAgent
```

#### Constructor

```python
CompetitionCodingAgent(remove_thinking=False, max_tests=2, public_test_only=True)
```

**Parameters:**
- `remove_thinking` (bool): Whether to remove thinking tags. Default: False
- `max_tests` (int): Maximum number of test cases to show. Default: 2
- `public_test_only` (bool): Whether to show only public test cases. Default: True

#### Attributes

- `revise_instruction` (str): Instruction for code revision
- `max_tests` (int): Maximum test cases to display
- `public_test_only` (bool): Flag for test case filtering

#### Methods

##### `format_test_results(test_results)`

Formats test results for display to the agent.

**Parameters:**
- `test_results` (List[Dict]): List of test result dictionaries

**Returns:** `str` - Formatted test results string

#### Example Usage

```python
agent = CompetitionCodingAgent(
    remove_thinking=False,
    max_tests=3,
    public_test_only=True
)

# Agent will iteratively improve code based on test feedback
```

---

### SWEAgent

Software engineering agent for GitHub issue resolution and code editing.

```python
from rllm.agents import SWEAgent
```

#### Constructor

```python
SWEAgent(use_fn_calling=False, format_model_response=False)
```

**Parameters:**
- `use_fn_calling` (bool): Whether to use function calling. Default: False
- `format_model_response` (bool): Whether to format model responses. Default: False

#### Attributes

- `use_fn_calling` (bool): Flag for function calling mode
- `format_model_response` (bool): Flag for response formatting
- `system_prompt` (str): System prompt for software engineering tasks
- `user_prompt_template` (str): Template for user prompts

#### Methods

##### `process_model_response(response)`

Processes model response to extract thought and action.

**Parameters:**
- `response` (str): Raw model response

**Returns:** `Tuple[str, Dict]` - Action string and processed response dict

#### Example Usage

```python
# With function calling
agent = SWEAgent(use_fn_calling=True, format_model_response=True)

# With XML parsing
agent = SWEAgent(use_fn_calling=False, format_model_response=False)
```

---

### WebArenaAgent

Specialized agent for WebArena benchmark tasks.

```python
from rllm.agents import WebArenaAgent
```

#### Constructor

```python
WebArenaAgent()
```

Features advanced web navigation and multimodal capabilities for WebArena-specific tasks.

---

### FrozenLakeAgent

Domain-specific agent for FrozenLake reinforcement learning environments.

```python
from rllm.agents import FrozenLakeAgent
```

#### Constructor

```python
FrozenLakeAgent()
```

Optimized for discrete action spaces and policy learning in grid-world environments.

---

## System Prompts

System prompts are defined in `rllm.agents.system_prompts` and used by agents to define their behavior.

### Available Prompts

- `SYSTEM_WEB_PROMPT`: For general web browsing tasks
- `SYSTEM_WEBARENA_PROMPT`: For WebArena benchmark tasks
- `SWE_SYSTEM_PROMPT`: For software engineering tasks (XML format)
- `SWE_SYSTEM_PROMPT_FN_CALL`: For software engineering tasks (function calling)
- `SWE_USER_PROMPT`: User prompt template for SWE tasks
- `SWE_USER_PROMPT_FN_CALL`: User prompt template for SWE function calling
- `TOOL_SYSTEM_PROMPT`: For tool-using agents

### Usage

```python
from rllm.agents.system_prompts import TOOL_SYSTEM_PROMPT

# System prompts are automatically used by agents
# but can be accessed for customization
```

---

## Utilities

### Message Processing

Extract recent conversation context from chat completions:

```python
from rllm.agents.utils import get_recent_assistant_user_messages

assistant_msg, env_messages = get_recent_assistant_user_messages(
    chat_completions_messages
)
```

**Parameters:**
- `chat_completions_messages` (List[Dict]): List of chat completion messages

**Returns:** `Tuple[Dict, List[Dict]]` - Most recent assistant message and environment messages

### Token Conversion

Convert messages to tokens and masks for training:

```python
from rllm.agents.utils import convert_messages_to_tokens_and_masks

tokens, masks = convert_messages_to_tokens_and_masks(
    messages=messages,
    tokenizer=tokenizer,
    parser=parser,
    contains_first_msg=False,
    contains_generation_msg=False
)
```

**Parameters:**
- `messages` (List[Dict]): List of messages to convert
- `tokenizer`: HuggingFace tokenizer instance
- `parser`: Chat template parser
- `contains_first_msg` (bool): Whether first message is special. Default: False
- `contains_generation_msg` (bool): Whether last message is special. Default: False

**Returns:** `Tuple[List[int], List[int]]` - Token IDs and attention masks

---

## Error Handling

### Common Issues

1. **Empty Trajectory**: Calling `get_current_state()` before any steps
   - Solution: Check `len(agent.trajectory.steps) > 0` before calling

2. **Invalid Model Response**: Model response doesn't match expected format
   - Solution: Implement robust parsing with fallbacks

3. **Tool Parsing Errors**: Tool calls can't be parsed from model response
   - Solution: Use try-except blocks and default to text responses

### Best Practices

1. Always call `reset()` before starting a new episode
2. Handle both string and structured model responses
3. Implement proper error handling in custom agents
4. Use the provided utilities for message processing
5. Test agents with various environment configurations

---

## Examples

### Basic Agent Usage

```python
from rllm.agents import MathAgent

# Initialize agent
agent = MathAgent()

# Simulate environment interaction
observation = {"question": "What is 2 + 2?"}
agent.update_from_env(observation, 0.0, False, {})

# Get messages for model
messages = agent.chat_completions

# Simulate model response
response = "Let me think step by step. 2 + 2 = 4. \\boxed{4}"
agent.update_from_model(response)

# Get current state
current_step = agent.get_current_state()
print(f"Action: {current_step.action}")
print(f"Thought: {current_step.thought}")
```

### Custom Agent Implementation

```python
from rllm.agents.agent import BaseAgent, Step, Trajectory

class MyAgent(BaseAgent):
    def __init__(self):
        self._trajectory = Trajectory()
        self.messages = []
        self.step = 0
        
    def update_from_env(self, observation, reward, done, info, **kwargs):
        # Implementation here
        pass
        
    def update_from_model(self, response, **kwargs):
        # Implementation here  
        pass
        
    def reset(self):
        self._trajectory = Trajectory()
        self.messages = []
        self.step = 0
        
    def get_current_state(self):
        return self._trajectory.steps[-1] if self._trajectory.steps else None
    
    @property
    def chat_completions(self):
        return self.messages
    
    @property
    def trajectory(self):
        return self._trajectory
``` 