{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import json\n",
    "\n",
    "train_dataset = load_dataset(\"KodCode/KodCode-V1\", split=\"train\")\n",
    "print(\"Training set:\", train_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Rules\n",
    "\n",
    "`style`: instruct\n",
    "\n",
    "`subset`: Leetcode, Codeforces, Code Contests, Taco, Apps\n",
    "\n",
    "`GPT4o Pass Count`: < 9\n",
    "\n",
    "`Benchmark Similarity`: < 0.9\n",
    "\n",
    "Test count: >= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset to include only specific styles\n",
    "filtered_train_dataset = train_dataset.filter(lambda x: x['subset'] in ['Leetcode', 'Codeforces', 'Code_Contests', 'Apps', 'Taco'])\n",
    "# Filter for 'instruct' style\n",
    "instruct_dataset = filtered_train_dataset.filter(lambda x: x['style'] == 'instruct')\n",
    "# Filter for gpt_pass_trial_num < 10\n",
    "low_trials_dataset = instruct_dataset.filter(lambda x: x['gpt_pass_trial_num'] < 9)\n",
    "# Filter for benchmark similarity < 0.9\n",
    "high_quality_dataset = low_trials_dataset.filter(lambda x: x['benchmark_similarity'] < 0.9)\n",
    "# Filter for test codes with >= 4 'def' occurrences\n",
    "def_filtered_dataset = high_quality_dataset.filter(lambda x: x['test_code'].count('def') >= 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bad Data Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ids = [\"Codeforces_12376_I\"]\n",
    "error_filtered_dataset = def_filtered_dataset.filter(lambda x: x['question_id'] not in bad_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_test_info(test_info):\n",
    "    \"\"\"\n",
    "    Format test_info into Python starter code with docstring and function declaration.\n",
    "    \n",
    "    Args:\n",
    "        test_info: List of test info dictionaries containing function declaration and docstring\n",
    "        \n",
    "    Returns:\n",
    "        Formatted Python starter code string\n",
    "    \"\"\"\n",
    "    # Return empty if no test info\n",
    "    if not test_info:\n",
    "        return \"\"\n",
    "        \n",
    "    # Get the function declaration and docstring from first test info\n",
    "    func_dec = test_info[0]['function_declaration']\n",
    "    \n",
    "    # Format the code\n",
    "    code = [func_dec]\n",
    "    # Add any other function declarations from remaining test infos\n",
    "    for test in test_info[1:]:\n",
    "        if 'function_declaration' in test:\n",
    "            code.append(test['function_declaration'])\n",
    "\n",
    "    starter_code = \"\\n\".join(code)\n",
    "\n",
    "    instruction = f\"Use the following starter code for your solution:\\n\\n{starter_code}\\n\"\n",
    "        \n",
    "    return instruction\n",
    "\n",
    "inst = format_test_info(error_filtered_dataset[66]['test_info'])\n",
    "print(inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_imports(import_line):\n",
    "    # Extract everything after \"from solution import \"\n",
    "    if not import_line.startswith(\"from solution import\"):\n",
    "        return \"\"\n",
    "    \n",
    "    imports = import_line.replace(\"from solution import \", \"\").strip()\n",
    "    \n",
    "    # Convert to starter code format\n",
    "    instruction = f\"The code you write must contain the following functions or classes:\\n{imports}\\n\"\n",
    "            \n",
    "    return instruction\n",
    "\n",
    "# Extract imports from test code\n",
    "imported_names = extract_imports('\\n'.join([line for line in error_filtered_dataset[0]['test_code'].split('\\n') if line.strip().startswith('from solution import')]))\n",
    "print(imported_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for entry in error_filtered_dataset:\n",
    "    tests = entry['test_code']\n",
    "    solution_import = '\\n'.join([line for line in tests.split('\\n') if line.strip().startswith('from solution import')])\n",
    "    tests = '\\n'.join([line for line in tests.split('\\n') if not line.strip().startswith('from solution import')])\n",
    "    \n",
    "    test_info = entry['test_info']\n",
    "    if not test_info:\n",
    "        instruction = extract_imports(solution_import)\n",
    "    else:\n",
    "        instruction = format_test_info(test_info)\n",
    "    \n",
    "    problem =  f\"\"\"\n",
    "Please solve the programming task below using a self-contained code snippet in a markdown code block.\n",
    "    \n",
    "{entry['question'].strip()}\n",
    "\n",
    "{instruction}\n",
    "\"\"\"\n",
    "    \n",
    "    if len(tests) == 0:\n",
    "        continue\n",
    "    new_entry = {\n",
    "        \"problem\": problem,\n",
    "        \"solutions\": entry[\"solution\"],\n",
    "        \"tests\": tests,\n",
    "    }\n",
    "    \n",
    "    dataset.append(new_entry)\n",
    "\n",
    "print(f'Dataset size: {len(dataset)}')\n",
    "\n",
    "output_dir = os.path.abspath(\"../../train/code\")\n",
    "output_file = os.path.join(output_dir, \"kodcode.json\")\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(dataset, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rllm-roy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
