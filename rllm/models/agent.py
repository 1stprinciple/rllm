from abc import ABC, abstractmethod

class BaseAgent(ABC):
    @abstractmethod
    def _pre_get_action(self, obs_act_seq):
        """
        Prepares the input for model query by formatting the observation-action 
        trajectory into the ChatML format.

        Args:
            obs_act_seq (List[Any]): The current trajectory containing observations and actions. The newest observation is at the end.

        Returns:
            List[Dict[str, str]]: A list of dictionaries formatted in ChatML, where each dictionary
            contains a "role" (e.g., "system", "user") and "content" (the corresponding text).
        """
        return [
            {"role": "system", "content": ""},
            {"role": "user", "content": ""},
        ]

    @abstractmethod
    def _post_get_action(self, response):
        """
        Processes the response generated by `get_action` and extracts the final action.

        Args:
            response (str): The raw response generated by the model.

        Returns:
            str: The extracted action as a string.
        """
        return response

    @abstractmethod
    def update(self, action, observation, next_observation, reward, terminated, truncated, info):
        """
        Updates the agent's internal state after an environment step.

        This function is called during environment interaction to incorporate the latest action's
        outcome into the agent's learning process.

        Args:
            action (str): The action taken by the agent.
            observation (Any): The observation before taking the action.
            next_observation (Any): The observation after taking the action.
            reward (float): The reward received after taking the action.
            terminated (bool): Whether the episode has ended due to termination.
            truncated (bool): Whether the episode has ended due to truncation.
            info (dict): Additional metadata from the environment.

        Returns:
            None
        """
        return

    @abstractmethod
    def reset(self):
        """
        Resets the agent's internal state, typically called at the beginning of a new episode.

        This function should clear any stored history or state information necessary 
        for a fresh interaction.

        Returns:
            None
        """
        return
    
    @abstractmethod
    def augment_reward(self, action, next_observation, reward):
        """
        Adjusts or augments the reward signal based on the action taken and the next observation.

        This function can be used to modify the reward structure dynamically, 
        for example, by adding intrinsic motivation or shaping rewards.

        Args:
            action (Any): The action taken by the agent.
            next_observation (Any): The resulting observation after the action.
            reward (float): The original reward from the environment.

        Returns:
            float: The modified reward value.
        """
        return reward