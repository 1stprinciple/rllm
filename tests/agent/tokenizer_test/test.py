from transformers import AutoTokenizer

# Load tokenizer (Qwen or any other model with chat_template)
# tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen1.5-0.5B", trust_remote_code=True)
# tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-1.5B", trust_remote_code=True)


tokenizer = AutoTokenizer.from_pretrained("deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B", trust_remote_code=True)
with open("./test.jinja", "r") as f:
    template_str = f.read()
    tokenizer.chat_template = template_str
    
token_str = tokenizer.decode([151648, 198, 32313, 11, 773, 358, 1184, 311, 5508, 279, 51424, 13934, 320, 15, 11, 220, 18, 8, 311, 24660, 13934, 13, 88190, 11, 358, 6099, 429, 24660, 13934, 525, 15251, 438, 320, 81, 11, 7851, 116, 701, 1380, 435, 374, 279, 6010, 504, 279, 6238, 311, 279, 1459, 11, 323, 7851, 116, 374, 279, 9210, 1865, 448, 279, 6785, 856, 35321, 13, 4710, 5338, 11, 358, 1265, 4658, 25529, 419, 700, 476, 50087, 279, 1459, 13, 758, 51424, 13934, 11, 279, 856, 80697, 374, 220, 15, 323, 279, 379, 80697, 374, 220, 18, 13, 2055, 11, 419, 1459, 374, 389, 279, 379, 35321, 11, 220, 18, 8153, 3403, 279, 6238, 13, 2938, 3643, 5530, 1576, 421, 856, 374, 220, 15, 11, 582, 2299, 2987, 389, 279, 379, 35321, 476, 279, 6238, 13, 8704, 379, 374, 6785, 11, 432, 594, 389, 279, 6785, 379, 35321, 382, 7039, 11, 311, 1477, 279, 24660, 13934, 11, 358, 1184, 311, 1477, 435, 323, 7851, 116, 13, 358, 6099, 279, 54079, 369, 33437, 504, 51424, 311, 24660, 13934, 525, 510, 12, 435, 284, 11995, 248, 7, 87, 29456, 488, 379, 29456, 340, 12, 7851, 116, 284, 796, 302, 276, 7021, 10776, 692, 4416, 11, 625, 35268, 304, 279, 2750, 11, 856, 374, 220, 15, 323, 379, 374, 220, 18, 382, 57908, 1095, 435, 1156, 510, 81, 284, 11995, 248, 7, 15, 29456, 488, 220, 18, 29456, 8, 284, 11995, 248, 7, 15, 488, 220, 24, 8, 284, 11995, 248, 24, 284, 220, 18, 382, 71486, 11, 773, 435, 374, 220, 18, 13, 2938, 3643, 5530, 1576, 279, 1459, 374, 220, 18, 8153, 3123, 504, 279, 6238, 382, 5847, 11, 7851, 116, 13, 7851, 116, 284, 796, 302, 276, 7021, 10776, 568, 1988, 1588, 11, 856, 374, 220, 15, 13, 2055, 11, 625, 35268, 304, 11, 582, 633, 7851, 116, 284, 796, 302, 276, 7, 18, 14, 15, 568, 13824, 11, 49702, 553, 7168, 13, 88190, 11, 796, 302, 276, 315, 54910, 30, 358, 6099, 429, 979, 856, 374, 220, 15, 323, 379, 374, 6785, 11, 279, 9210, 374, 51745, 14, 17, 11, 1576, 432, 594, 7678, 705, 3156, 279, 6785, 379, 35321, 382, 3983, 1077, 752, 1744, 803, 15516, 13, 8704, 856, 374, 220, 15, 323, 379, 374, 6785, 11, 582, 2299, 389, 279, 6785, 379, 35321, 13, 2055, 11, 279, 9210, 7851, 116, 374, 51745, 14, 17, 50784, 11, 892, 374, 220, 24, 15, 12348, 13, 4710, 3872, 1052, 264, 1616, 311, 4009, 419, 1667, 796, 302, 66451, 30, 8325, 11, 421, 856, 374, 220, 15, 323, 379, 374, 6785, 11, 796, 302, 276, 7021, 10776, 8, 374, 5614, 1576, 12804, 553, 7168, 13666, 13, 2055, 11, 304, 1741, 5048, 11, 582, 614, 311, 8253, 279, 9210, 3118, 389, 279, 93286, 13, 1988, 2474, 856, 374, 220, 15, 323, 379, 374, 6785, 11, 432, 594, 389, 279, 6785, 379, 35321, 11, 773, 7851, 116, 374, 51745, 14, 17, 382, 10061, 752, 10146, 429, 13, 358, 1414, 429, 304, 24660, 13934, 11, 7851, 116, 374, 16878, 504, 279, 6785, 856, 35321, 11, 2087, 1760, 2962, 1023, 4482, 13, 2055, 11, 979, 279, 1459, 374, 389, 279, 6785, 379, 35321, 11, 7851, 116, 374, 51745, 14, 17, 13, 2055, 11, 429, 1265, 387, 4396, 382, 54815, 11, 279, 24660, 13934, 525, 320, 18, 11, 51745, 14, 17, 568, 4710, 14190, 11, 1077, 752, 1779, 421, 358, 1521, 279, 28117, 1290, 13, 435, 52263, 374, 856, 52263, 5519, 379, 52263, 11, 773, 220, 15, 488, 220, 24, 11, 892, 374, 220, 24, 11, 773, 435, 374, 220, 18, 13, 2938, 594, 4396, 13, 1752, 7851, 116, 11, 2474, 856, 374, 220, 15, 11, 279, 1459, 374, 389, 279, 379, 35321, 11, 773, 7851, 116, 374, 51745, 14, 17, 13, 2055, 11, 9834, 11, 320, 18, 11, 51745, 14, 17, 8, 374, 4396, 382, 3872, 1052, 2441, 1616, 311, 1744, 911, 432, 30, 10696, 1667, 279, 4982, 12671, 30, 1913, 279, 4982, 12671, 11, 51745, 14, 17, 33210, 311, 320, 15, 11, 16, 701, 892, 374, 6896, 279, 1459, 582, 2299, 14550, 448, 11, 30690, 705, 553, 264, 8168, 315, 220, 18, 13, 2055, 11, 24660, 13934, 1281, 5530, 1588, 382, 92014, 11, 421, 358, 4038, 279, 21495, 14122, 553, 279, 6238, 11, 279, 1459, 320, 15, 11, 18, 701, 323, 279, 21615, 389, 279, 379, 35321, 13, 1084, 594, 264, 1290, 21495, 448, 14201, 220, 15, 323, 220, 18, 11, 773, 279, 9751, 65628, 810, 374, 220, 18, 11, 892, 374, 435, 13, 576, 9210, 7851, 116, 374, 220, 24, 15, 12348, 11, 892, 374, 51745, 14, 17, 50784, 13, 2055, 11, 429, 594, 12966, 382, 40, 1744, 358, 2776, 16506, 429, 279, 24660, 13934, 525, 320, 18, 11, 51745, 14, 17, 568, 2055, 11, 358, 1265, 3270, 429, 438, 279, 1590, 4226, 382, 334, 19357, 21806, 1019, 785, 24660, 13934, 525, 1124, 79075, 96065, 18, 11, 1124, 37018, 35702, 2493, 15170, 17, 5410, 27275, 151649, 271, 1249, 5508, 279, 51424, 13934, 1124, 1188, 15, 11, 220, 18, 10699, 8, 311, 24660, 13934, 11, 582, 990, 279, 54079, 369, 14409, 510, 12, 17767, 435, 284, 1124, 26888, 45340, 61, 17, 488, 379, 61, 17, 92, 1124, 340, 12, 17767, 1124, 15976, 284, 1124, 277, 302, 276, 59, 2359, 11520, 37018, 90, 88, 15170, 87, 11035, 1291, 8, 1124, 692, 22043, 279, 1459, 1124, 1188, 15, 11, 220, 18, 10699, 982, 12, 576, 856, 80697, 17767, 87, 57758, 374, 220, 15, 11, 323, 279, 379, 80697, 17767, 88, 57758, 374, 220, 18, 624, 12, 31359, 1095, 17767, 81, 59, 982, 220, 1124, 9640, 220, 435, 284, 1124, 26888, 90, 15, 61, 17, 488, 220, 18, 61, 17, 92, 284, 1124, 26888, 90, 15, 488, 220, 24, 92, 284, 1124, 26888, 90, 24, 92, 284, 220, 18, 198, 220, 1124, 921, 12, 31359, 1095, 1124, 11520, 15976, 59, 982, 220, 1124, 9640, 220, 1124, 15976, 284, 1124, 277, 302, 276, 59, 2359, 11520, 37018, 90, 18, 15170, 15, 11035, 1291, 340, 220, 1124, 921, 220, 8704, 17767, 87, 284, 220, 15, 57758, 323, 17767, 88, 57758, 374, 6785, 11, 279, 1459, 15448, 389, 279, 6785, 379, 35321, 11, 773, 1124, 11520, 15976], skip_special_tokens=False)
print(repr(token_str))
print("\n\n\n\n new content: \n")
encode_decode_again = tokenizer.decode(tokenizer.encode(token_str, add_special_tokens=False))
print(repr(encode_decode_again))
print("\n\n\n\n new content: \n")
msg = {"role": "assistant", "content": token_str}
msg_str = tokenizer.apply_chat_template(
            [msg], tokenize=False, add_generation_prompt=False,
        )
decoded_msg = tokenizer.decode(tokenizer.encode(msg_str, add_special_tokens=False))
print(repr(decoded_msg))


# # Test messages
# messages = [
#     {"role": "user", "content": "What is your name?"},
#     {"role": "assistant", "content": "I am Qwen."},
#     {"role": "user", "content": "What can you do?"},
#     {"role": "assistant", "content": "I can answer your questions."}
# ]

# # 1. Apply chat template for generation-time prompt of B
# gen_prompt = tokenizer.apply_chat_template(messages[:1], tokenize=False, add_generation_prompt=True)
# print(f"Generation time prompt after chat template: {repr(gen_prompt)}")
# gen_prompt_ids = tokenizer(gen_prompt, add_special_tokens=False).input_ids

# # 2. Apply chat template for full conversation [A, B, C, D]
# full_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)
# print(f"Full prompt after chat template: {repr(full_prompt)}")
# full_prompt_ids = tokenizer(full_prompt, add_special_tokens=False).input_ids

# # 3. Compare
# is_prefix = full_prompt_ids[:len(gen_prompt_ids)] == gen_prompt_ids

# print("Generation-time prompt is prefix of full prompt:", is_prefix)
# if not is_prefix:
#     print("Mismatch at index:")
#     for i, (a, b) in enumerate(zip(full_prompt_ids, gen_prompt_ids)):
#         if a != b:
#             print(f"  At token {i}: full={a}, gen={b}")
#             break

# print("\nDecoded generation-time prompt:")
# print(repr(tokenizer.decode(gen_prompt_ids)))

# print("\nDecoded full prompt prefix:")
# print(repr(tokenizer.decode(full_prompt_ids[:len(gen_prompt_ids)])))
